{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tensorflow-project/FineTuning/blob/main/Experiments/CosineSimilarity4emotions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/tensorflow-project/FineTuning"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHvXPnQkeyzf",
        "outputId": "7978ce90-6c17-4b18-c769-d71784546c3d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'FineTuning'...\n",
            "remote: Enumerating objects: 1817, done.\u001b[K\n",
            "remote: Counting objects: 100% (780/780), done.\u001b[K\n",
            "remote: Compressing objects: 100% (299/299), done.\u001b[K\n",
            "remote: Total 1817 (delta 578), reused 655 (delta 476), pack-reused 1037\u001b[K\n",
            "Receiving objects: 100% (1817/1817), 97.13 MiB | 17.35 MiB/s, done.\n",
            "Resolving deltas: 100% (1297/1297), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "from google.colab import drive\n",
        "import numpy as np\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import urllib.request\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "import csv\n",
        "from google.oauth2.credentials import Credentials\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.errors import HttpError\n",
        "\n",
        "### agree to mounting your Google Drive for saving the new weights later on\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "py_file_location = \"/content/FineTuning/four_emotions\"\n",
        "sys.path.append(os.path.abspath(py_file_location))\n",
        "py_file_location = \"/content/FineTuning/models\"\n",
        "sys.path.append(os.path.abspath(py_file_location))\n",
        "\n",
        "import textual_inversion_four_emotions as txt"
      ],
      "metadata": {
        "id": "SD_KkNtNSth_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78795ffa-5dc5-400b-e004-afe08c134c2a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for keras-cv (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (6.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.9/dist-packages (3.8.0)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.9/dist-packages (from h5py) (1.22.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### create an instance of the StableDiffusion() class\n",
        "stable_diffusion = txt.StableDiffusion()\n",
        "\n",
        "### our new concept which is later inserted in the different prompts (for training and image generation).\n",
        "###The goal is to create an embedding for our placeholder_token\n",
        "placeholder_token = \"\"\n",
        "\n",
        "\n",
        "### Add our placeholder_token to our stable_diffusion Model\n",
        "stable_diffusion.tokenizer.add_tokens(placeholder_token)\n",
        "\n",
        "train_ds = txt.create_dataset(stable_diffusion, placeholder_token)\n",
        "\n",
        "### beta is the diffusion rate \n",
        "noise_scheduler = txt.NoiseScheduler(\n",
        "    ### beta_start determines the amount of noise added at the start of the denoising process\n",
        "    beta_start=0.00085,\n",
        "    ### beta_end at the end of the denoising process\n",
        "    beta_end=0.012,\n",
        "    ### the beta_schedule determines that the diffusion rate increases linearly\n",
        "    beta_schedule=\"scaled_linear\",\n",
        "    train_timesteps=1000,\n",
        ")\n",
        "\n",
        "training_image_encoder = keras.Model(\n",
        "        stable_diffusion.image_encoder.input,\n",
        "        stable_diffusion.image_encoder.layers[-2].output,\n",
        "    )\n",
        "    \n",
        "    \n",
        "#EPOCHS = 50\n",
        "### learning rate decays depending on the number of epochs to avoid convergence issues in few epochs \n",
        "### in the originial tutorial a scheduler is used but we experienced to have better results without a scheduler\n",
        "\"\"\"learning_rate = keras.optimizers.schedules.CosineDecay(\n",
        "    initial_learning_rate=1e-4, decay_steps=train_ds.cardinality() * EPOCHS\n",
        ")\"\"\"\n",
        "### inizialize the optimizer\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    weight_decay=0.004, learning_rate=1e-4, epsilon=1e-8, global_clipnorm=10\n",
        ")\n",
        "\n",
        "txt.textual_preprocessing(stable_diffusion, placeholder_token)\n",
        "\n",
        "### embeddings for cosine similarity\n",
        "sticker_embedding = []\n",
        "cosine_similarity = []\n",
        "cosine_similarity.append(txt.cosine_sim(txt.get_embedding(\"broccoli\", stable_diffusion), txt.get_embedding(placeholder_token, stable_diffusion)))"
      ],
      "metadata": {
        "id": "j6M4tCdlGhgm",
        "outputId": "5a63b1a3-bbca-4d1d-9941-ea064827484f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "By using this model checkpoint, you acknowledge that its usage is subject to the terms of the CreativeML Open RAIL-M license at https://raw.githubusercontent.com/CompVis/stable-diffusion/main/LICENSE\n",
            "Downloading data from https://github.com/openai/CLIP/blob/main/clip/bpe_simple_vocab_16e6.txt.gz?raw=true\n",
            "1356917/1356917 [==============================] - 0s 0us/step\n",
            "Downloading data from https://i.imgur.com/9zAwPyt.jpg\n",
            "8784/8784 [==============================] - 0s 0us/step\n",
            "Downloading data from https://i.imgur.com/qCNFRl4.jpg\n",
            "14548/14548 [==============================] - 0s 1us/step\n",
            "Downloading data from https://i.imgur.com/YLnylVr.png\n",
            "202761/202761 [==============================] - 0s 2us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://i.imgur.com/hFqqp3p.jpg\n",
            "7870/7870 [==============================] - 0s 0us/step\n",
            "Downloading data from https://i.imgur.com/uGkSrzg.jpg\n",
            "10306/10306 [==============================] - 0s 0us/step\n",
            "Downloading data from https://i.imgur.com/zTVXw0D.png\n",
            "172078/172078 [==============================] - 0s 2us/step\n",
            "Downloading data from https://i.imgur.com/XJxG3f0.png\n",
            "202377/202377 [==============================] - 0s 2us/step\n",
            "Downloading data from https://i.imgur.com/hlkuxBX.jpg\n",
            "11991/11991 [==============================] - 0s 1us/step\n",
            "Downloading data from https://i.imgur.com/kPH9XIh.jpg\n",
            "14897/14897 [==============================] - 0s 1us/step\n",
            "Downloading data from https://i.imgur.com/OR2oxyK.jpg\n",
            "8773/8773 [==============================] - 0s 0us/step\n",
            "Downloading data from https://i.imgur.com/mZswnIx.jpg\n",
            "6822/6822 [==============================] - 0s 0us/step\n",
            "Downloading data from https://i.imgur.com/TmlHZRY.png\n",
            "141537/141537 [==============================] - 0s 3us/step\n",
            "Downloading data from https://i.imgur.com/BmVIZlO.png\n",
            "201997/201997 [==============================] - 0s 2us/step\n",
            "Downloading data from https://huggingface.co/fchollet/stable-diffusion/resolve/main/vae_encoder.h5\n",
            "136824240/136824240 [==============================] - 1s 0us/step\n",
            "Downloading data from https://huggingface.co/fchollet/stable-diffusion/resolve/main/kcv_encoder.h5\n",
            "492466864/492466864 [==============================] - 2s 0us/step\n",
            "Downloading data from https://huggingface.co/fchollet/stable-diffusion/resolve/main/kcv_diffusion_model.h5\n",
            "3439090152/3439090152 [==============================] - 42s 0us/step\n",
            "Downloading data from https://huggingface.co/fchollet/stable-diffusion/resolve/main/kcv_decoder.h5\n",
            "198180272/198180272 [==============================] - 2s 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/FineTuning/four_emotions/textual_inversion_four_emotions.py:536: RuntimeWarning: invalid value encountered in float_scalars\n",
            "  sim = dot(e1, e2)/(norm(e1)*norm(e2))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### how long to train for\n",
        "epochs = 2\n",
        "epoch_num = list(range(epochs+1))\n",
        "txt.training(epochs, stable_diffusion, train_ds, sticker_embedding, cosine_similarity, stable_diffusion, noise_scheduler, training_image_encoder, optimizer, placeholder_token)"
      ],
      "metadata": {
        "id": "LD07AvQddezX",
        "outputId": "664e51f5-aacf-495d-ee26-5fe190fa8b3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/2:   0%|          | 0/535 [00:00<?, ?it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### where to store your newly generated weights\n",
        "path = '/content/drive/MyDrive/weights_four_emotions.npy'"
      ],
      "metadata": {
        "id": "o4OtGsg46sfZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### get the weights of the text encoder and save the to Google Drive\n",
        "text_encoder_weights = np.array(stable_diffusion.text_encoder.get_weights(), dtype=object)\n",
        "\n",
        "### save the weights array to a file on your Google Drive\n",
        "np.save(path, text_encoder_weights)"
      ],
      "metadata": {
        "id": "1wBN4HdceChs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/'"
      ],
      "metadata": {
        "id": "dUk7L_UBkjBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()  # Create a new figure\n",
        "plt.plot(epoch_num, cosine_similarity, 'darkblue')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Cosine Similarity')\n",
        "plt.title('Cosine Similarity')\n",
        "plt.show()\n",
        "plt.savefig('/content/drive/MyDrive/Images/plot.jpg')"
      ],
      "metadata": {
        "id": "xK-Sa-nsOYJO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}