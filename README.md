# Fine-Tuning (Tensorflow)
Using textual inversion to fine tune keras' Stable Diffusion model in order to combine two rather opposed concepts like broccoli and emotions in a certain style in Tensorflow. Training and testing a pre-trained ResNet to classify the emotion depicted in the generated images. 

# Usage: 
The code for training the finetuning model and generating images is to be found in the folders "four_emotions" and "two_concepts". Each includes a training.ipynb which can be used for training new weigths on the task, a textual_inversion.py and an image_generation.ipynb, which can be used for generating new images of broccoli with emotions, using either own pre-trained weights or weights provided by us. 

Choose whether to use "four_emotions" or "two_concepts" depending on whether you want images generated by training on the emotions "happy", "sad", "angry" and "in love" at the same time or whether to train the concept of a broccoli sticker and the concept of a happy emoji simultaneously and later combining them.

For training, you can either continue with weigths saved in a numpy array or start a new training. 
For the former, mount your Google Drive and insert the name of your own numpy array stored in your Google Drive where indicated in the coments:
![grafik](https://user-images.githubusercontent.com/126180162/227212836-009d77b6-b7c0-4257-9577-73ae9907c0ed.png)
Afterwards, choose how many epochs you want to train for, whther to train with seeing the development of the image after each epoch or not, and where to save your new weights: 
![grafik](https://user-images.githubusercontent.com/126180162/227213077-d4e3979b-a3f0-4716-ac3b-6b6aafbc3abf.png)

For image generation, choose where to loas weights from. Either execute the code as ist is and load our pre-trained weights, or insert your own path. 
![grafik](https://user-images.githubusercontent.com/126180162/227211476-18cbd088-8e15-4857-9a11-94b715a891eb.png)
Afterwards, you can choose a prompt, the number of images to be generated and a fixed seed if wanted. 
![grafik](https://user-images.githubusercontent.com/126180162/227211216-62c90d49-9c95-4fad-adae-f85cbee5f2dd.png)

Execute the cell for storing the images in your Google Drive or the one for showing the images in the notebook. You may have to save a folder "Images" in you Google Drive before doing so.
![grafik](https://user-images.githubusercontent.com/126180162/227211627-7f07917b-b036-4314-9210-491888e6907f.png)

When generating images with two concepts, choose the percentage of emoji the images should contain and whether to generate images by concept interpolation:
![grafik](https://user-images.githubusercontent.com/126180162/227212231-b418f3f2-cd04-449b-bd16-39344827c06e.png)
or by combining concepts in the prompt:
![grafik](https://user-images.githubusercontent.com/126180162/227212329-d003c75d-a572-4347-82db-b328de7ecf4c.png)

The file "ResNet.ipynb" contains the pre-trained, customized ResNet50 used by us including image preprocessing. The images used are stored in the folder "dataset" and contain only images that contain enough features of broccoli and the respective emotion.

# License: 
We use pre-trained models and the pre-trained ResNet50 model from Keras which are licensed under the Apache License, Version 2.0. You may obtain a copy of the License at https://www.apache.org/licenses/LICENSE-2.0 (Copyright 2022 The KerasCV Authors).


# Acknowledgments:
We use the  keras-cv Stable diffusion model.\
Link to keras-cv Github: [https://github.com/tensorflow-project/keras-cv](https://github.com/keras-team/keras-cv/tree/master/keras_cv/models/stable_diffusion) .

Furthermore, we customize the keras-cv ResNet50.\
Link to keras-cv Github: https://github.com/keras-team/keras-applications/blob/master/keras_applications/resnet50.py .

