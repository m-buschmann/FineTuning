{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tensorflow-project/FineTuning/blob/main/four_emotions/image_generation_four_emotions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/tensorflow-project/FineTuning"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHvXPnQkeyzf",
        "outputId": "c6098424-8c14-4d57-b290-b6a257ac4199"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'FineTuning'...\n",
            "remote: Enumerating objects: 1880, done.\u001b[K\n",
            "remote: Counting objects: 100% (843/843), done.\u001b[K\n",
            "remote: Compressing objects: 100% (362/362), done.\u001b[K\n",
            "remote: Total 1880 (delta 621), reused 655 (delta 476), pack-reused 1037\u001b[K\n",
            "Receiving objects: 100% (1880/1880), 127.23 MiB | 24.23 MiB/s, done.\n",
            "Resolving deltas: 100% (1340/1340), done.\n",
            "Updating files: 100% (38/38), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "import urllib.request\n",
        "\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "py_file_location = \"/content/FineTuning/four_emotions\"\n",
        "sys.path.append(os.path.abspath(py_file_location))\n",
        "py_file_location = \"/content/FineTuning/models\"\n",
        "sys.path.append(os.path.abspath(py_file_location))\n",
        "\n",
        "import textual_inversion_four_emotions as txt"
      ],
      "metadata": {
        "id": "SD_KkNtNSth_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "601713c8-54b6-415e-c8b0-fee641f6629e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for keras-cv (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (6.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.9/dist-packages (3.8.0)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.9/dist-packages (from h5py) (1.22.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### load stable diffusion class and placeholder token from textual_inversion.py\n",
        "stable_diffusion = txt.StableDiffusion()\n",
        "placeholder_token = \"<my-broccoli-token>\"\n",
        "txt.adding_token(stable_diffusion, placeholder_token)"
      ],
      "metadata": {
        "id": "txmTOwxFoH5O",
        "outputId": "6d920cdd-c218-497b-8137-2fe52d158d2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "By using this model checkpoint, you acknowledge that its usage is subject to the terms of the CreativeML Open RAIL-M license at https://raw.githubusercontent.com/CompVis/stable-diffusion/main/LICENSE\n",
            "Downloading data from https://github.com/openai/CLIP/blob/main/clip/bpe_simple_vocab_16e6.txt.gz?raw=true\n",
            "1356917/1356917 [==============================] - 0s 0us/step\n",
            "Downloading data from https://huggingface.co/fchollet/stable-diffusion/resolve/main/kcv_encoder.h5\n",
            "492466864/492466864 [==============================] - 5s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### for downloading weights from dropbox:\n",
        "### if you want to use any other service than dropbox, change the code underneath\n",
        "### Replace  and  with the ID and name of your file\n",
        "\n",
        "### The file id is the string of characters between \"s/\" and the next slash \"/\"\n",
        "### example: https://www.dropbox.com/s/28lsilu4rltrioj/LR5weightsAllEmotions30epochs.npy?dl=0\n",
        "file_id = '28lsilu4rltrioj'\n",
        "\n",
        "### name Ã³f file\n",
        "file_name = 'LR5weightsAllEmotions40epochs.npy'\n",
        "\n",
        "url = f'https://www.dropbox.com/s/{file_id}/{file_name}?dl=1'\n",
        "filename = f'{file_name}.npy'\n",
        "     \n"
      ],
      "metadata": {
        "id": "ZnDt4BHJd40N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Download the file from the URL and save it locally\n",
        "urllib.request.urlretrieve(url, filename=filename)\n",
        "\n",
        "### Load the saved numpy file using numpy.load()\n",
        "weights = np.load(filename, allow_pickle=True)\n",
        "\n",
        "### Set the weights of the text encoder\n",
        "stable_diffusion.text_encoder.set_weights(weights)"
      ],
      "metadata": {
        "id": "bsNpooPgeLHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### insert your prompt here\n",
        "prompt = f\"a {placeholder_token} in love .\"\n",
        "### choose how many images should be generated\n",
        "number = 1\n",
        "### choose a seed, use None for random genration\n",
        "SEED = 2332"
      ],
      "metadata": {
        "id": "Dow5AkAtkaR-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### EITHER:\n",
        "### generate images and save them directly in your Google Drive\n",
        "### where to store your images, you may have to create the folder \"Images\" first\n",
        "drive_folder = '/content/drive/MyDrive/Images/'\n",
        "\n",
        "txt.image_generation(prompt, drive_folder, number, stable_diffusion, seed=SEED, number_steps = 50)"
      ],
      "metadata": {
        "id": "b6_FS5jfeROz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76b3a426-e497-43d7-8c53-091d9887665c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50/50 [==============================] - 75s 1s/step\n",
            "50/50 [==============================] - 57s 1s/step\n",
            "50/50 [==============================] - 57s 1s/step\n",
            "50/50 [==============================] - 57s 1s/step\n",
            "50/50 [==============================] - 57s 1s/step\n",
            "50/50 [==============================] - 57s 1s/step\n",
            "50/50 [==============================] - 57s 1s/step\n",
            "50/50 [==============================] - 57s 1s/step\n",
            "50/50 [==============================] - 57s 1s/step\n",
            "50/50 [==============================] - 57s 1s/step\n",
            "50/50 [==============================] - 57s 1s/step\n",
            "50/50 [==============================] - 57s 1s/step\n",
            "50/50 [==============================] - 57s 1s/step\n",
            "50/50 [==============================] - 57s 1s/step\n",
            "50/50 [==============================] - 57s 1s/step\n",
            "50/50 [==============================] - 57s 1s/step\n",
            "50/50 [==============================] - 57s 1s/step\n",
            "50/50 [==============================] - 57s 1s/step\n",
            "50/50 [==============================] - 58s 1s/step\n",
            "50/50 [==============================] - 57s 1s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### OR:\n",
        "### generate images and plot them here\n",
        "### change seed if you want different images with same weights\n",
        "generated = stable_diffusion.text_to_image(\n",
        "    prompt , batch_size=number, num_steps=30, seed=SEED\n",
        ")\n",
        "txt.plot_images(generated)"
      ],
      "metadata": {
        "id": "os7FbglCqUDg",
        "outputId": "13871173-b772-4118-ceb5-fa4b3b5160ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://huggingface.co/fchollet/stable-diffusion/resolve/main/kcv_diffusion_model.h5\n",
            " 723910656/3439090152 [=====>........................] - ETA: 22s"
          ]
        }
      ]
    }
  ]
}