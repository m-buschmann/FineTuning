{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tensorflow-project/stable-diffusion/blob/main/keras_cv_diffusion_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x6ubtxhf-sbL"
      },
      "outputs": [],
      "source": [
        "# Copyright 2022 The KerasCV Authors\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from keras_cv.models.stable_diffusion.__internal__.layers.padded_conv2d import (\n",
        "    PaddedConv2D,\n",
        ")\n",
        "\n",
        "\n",
        "class DiffusionModel(keras.Model):\n",
        "    \"\"\" the U-Net for our stable diffusion, used for downsampling and upsampling of the image starting with random noise but where is the call?\"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        img_height,\n",
        "        img_width,\n",
        "        max_text_length,\n",
        "        name=None,\n",
        "        download_weights=True,\n",
        "    ):\n",
        "        context = keras.layers.Input((max_text_length, 768))\n",
        "        t_embed_input = keras.layers.Input((320,))\n",
        "        latent = keras.layers.Input((img_height // 8, img_width // 8, 4))\n",
        "\n",
        "        t_emb = keras.layers.Dense(1280)(t_embed_input)\n",
        "        t_emb = keras.layers.Activation(\"swish\")(t_emb)\n",
        "        t_emb = keras.layers.Dense(1280)(t_emb)\n",
        "\n",
        "        # Downsampling flow\n",
        "        ### save the different downsampling steps to improve later upsampling\n",
        "        outputs = []\n",
        "        x = PaddedConv2D(320, kernel_size=3, padding=1)(latent)\n",
        "        outputs.append(x)\n",
        "\n",
        "        for _ in range(2):\n",
        "            x = ResBlock(320)([x, t_emb])\n",
        "            x = SpatialTransformer(8, 40, fully_connected=False)([x, context])\n",
        "            outputs.append(x)\n",
        "        x = PaddedConv2D(320, 3, strides=2, padding=1)(x)  # Downsample 2x\n",
        "        outputs.append(x)\n",
        "\n",
        "        for _ in range(2):\n",
        "            x = ResBlock(640)([x, t_emb])\n",
        "            x = SpatialTransformer(8, 80, fully_connected=False)([x, context])\n",
        "            outputs.append(x)\n",
        "        x = PaddedConv2D(640, 3, strides=2, padding=1)(x)  # Downsample 2x\n",
        "        outputs.append(x)\n",
        "\n",
        "        for _ in range(2):\n",
        "            x = ResBlock(1280)([x, t_emb])\n",
        "            x = SpatialTransformer(8, 160, fully_connected=False)([x, context])\n",
        "            outputs.append(x)\n",
        "        x = PaddedConv2D(1280, 3, strides=2, padding=1)(x)  # Downsample 2x\n",
        "        outputs.append(x)\n",
        "\n",
        "        for _ in range(2):\n",
        "            x = ResBlock(1280)([x, t_emb])\n",
        "            outputs.append(x)\n",
        "\n",
        "        # Middle flow\n",
        "\n",
        "        x = ResBlock(1280)([x, t_emb])\n",
        "        x = SpatialTransformer(8, 160, fully_connected=False)([x, context])\n",
        "        x = ResBlock(1280)([x, t_emb])\n",
        "\n",
        "        # Upsampling flow\n",
        "\n",
        "        for _ in range(3):\n",
        "            ### using the outputs of the downsampling steps to improve the upsampling\n",
        "            x = keras.layers.Concatenate()([x, outputs.pop()])\n",
        "            x = ResBlock(1280)([x, t_emb])\n",
        "        x = Upsample(1280)(x)\n",
        "\n",
        "        for _ in range(3):\n",
        "            x = keras.layers.Concatenate()([x, outputs.pop()])\n",
        "            x = ResBlock(1280)([x, t_emb])\n",
        "            x = SpatialTransformer(8, 160, fully_connected=False)([x, context])\n",
        "        x = Upsample(1280)(x)\n",
        "\n",
        "        for _ in range(3):\n",
        "            x = keras.layers.Concatenate()([x, outputs.pop()])\n",
        "            x = ResBlock(640)([x, t_emb])\n",
        "            x = SpatialTransformer(8, 80, fully_connected=False)([x, context])\n",
        "        x = Upsample(640)(x)\n",
        "\n",
        "        for _ in range(3):\n",
        "            x = keras.layers.Concatenate()([x, outputs.pop()])\n",
        "            x = ResBlock(320)([x, t_emb])\n",
        "            x = SpatialTransformer(8, 40, fully_connected=False)([x, context])\n",
        "\n",
        "        # Exit flow\n",
        "\n",
        "        x = keras.layers.GroupNormalization(epsilon=1e-5)(x)\n",
        "        x = keras.layers.Activation(\"swish\")(x)\n",
        "        output = PaddedConv2D(4, kernel_size=3, padding=1)(x)\n",
        "\n",
        "        super().__init__([latent, t_embed_input, context], output, name=name)\n",
        "\n",
        "        if download_weights:\n",
        "            diffusion_model_weights_fpath = keras.utils.get_file(\n",
        "                origin=\"https://huggingface.co/fchollet/stable-diffusion/resolve/main/kcv_diffusion_model.h5\",\n",
        "                file_hash=\"8799ff9763de13d7f30a683d653018e114ed24a6a819667da4f5ee10f9e805fe\",\n",
        "            )\n",
        "            self.load_weights(diffusion_model_weights_fpath)\n",
        "\n",
        "\n",
        "class DiffusionModelV2(keras.Model):\n",
        "    def __init__(\n",
        "        self,\n",
        "        img_height,\n",
        "        img_width,\n",
        "        max_text_length,\n",
        "        name=None,\n",
        "        download_weights=True,\n",
        "    ):\n",
        "        context = keras.layers.Input((max_text_length, 1024))\n",
        "        t_embed_input = keras.layers.Input((320,))\n",
        "        latent = keras.layers.Input((img_height // 8, img_width // 8, 4))\n",
        "\n",
        "        t_emb = keras.layers.Dense(1280)(t_embed_input)\n",
        "        t_emb = keras.layers.Activation(\"swish\")(t_emb)\n",
        "        t_emb = keras.layers.Dense(1280)(t_emb)\n",
        "\n",
        "        # Downsampling flow\n",
        "\n",
        "        outputs = []\n",
        "        x = PaddedConv2D(320, kernel_size=3, padding=1)(latent)\n",
        "        outputs.append(x)\n",
        "\n",
        "        for _ in range(2):\n",
        "            x = ResBlock(320)([x, t_emb])\n",
        "            x = SpatialTransformer(5, 64, fully_connected=True)([x, context])\n",
        "            outputs.append(x)\n",
        "        x = PaddedConv2D(320, 3, strides=2, padding=1)(x)  # Downsample 2x\n",
        "        outputs.append(x)\n",
        "\n",
        "        for _ in range(2):\n",
        "            x = ResBlock(640)([x, t_emb])\n",
        "            x = SpatialTransformer(10, 64, fully_connected=True)([x, context])\n",
        "            outputs.append(x)\n",
        "        x = PaddedConv2D(640, 3, strides=2, padding=1)(x)  # Downsample 2x\n",
        "        outputs.append(x)\n",
        "\n",
        "        for _ in range(2):\n",
        "            x = ResBlock(1280)([x, t_emb])\n",
        "            x = SpatialTransformer(20, 64, fully_connected=True)([x, context])\n",
        "            outputs.append(x)\n",
        "        x = PaddedConv2D(1280, 3, strides=2, padding=1)(x)  # Downsample 2x\n",
        "        outputs.append(x)\n",
        "\n",
        "        for _ in range(2):\n",
        "            x = ResBlock(1280)([x, t_emb])\n",
        "            outputs.append(x)\n",
        "\n",
        "        # Middle flow\n",
        "\n",
        "        x = ResBlock(1280)([x, t_emb])\n",
        "        x = SpatialTransformer(20, 64, fully_connected=True)([x, context])\n",
        "        x = ResBlock(1280)([x, t_emb])\n",
        "\n",
        "        # Upsampling flow\n",
        "\n",
        "        for _ in range(3):\n",
        "            x = keras.layers.Concatenate()([x, outputs.pop()])\n",
        "            x = ResBlock(1280)([x, t_emb])\n",
        "        x = Upsample(1280)(x)\n",
        "\n",
        "        for _ in range(3):\n",
        "            x = keras.layers.Concatenate()([x, outputs.pop()])\n",
        "            x = ResBlock(1280)([x, t_emb])\n",
        "            x = SpatialTransformer(20, 64, fully_connected=True)([x, context])\n",
        "        x = Upsample(1280)(x)\n",
        "\n",
        "        for _ in range(3):\n",
        "            x = keras.layers.Concatenate()([x, outputs.pop()])\n",
        "            x = ResBlock(640)([x, t_emb])\n",
        "            x = SpatialTransformer(10, 64, fully_connected=True)([x, context])\n",
        "        x = Upsample(640)(x)\n",
        "\n",
        "        for _ in range(3):\n",
        "            x = keras.layers.Concatenate()([x, outputs.pop()])\n",
        "            x = ResBlock(320)([x, t_emb])\n",
        "            x = SpatialTransformer(5, 64, fully_connected=True)([x, context])\n",
        "\n",
        "        # Exit flow\n",
        "\n",
        "        x = keras.layers.GroupNormalization(epsilon=1e-5)(x)\n",
        "        x = keras.layers.Activation(\"swish\")(x)\n",
        "        output = PaddedConv2D(4, kernel_size=3, padding=1)(x)\n",
        "\n",
        "        super().__init__([latent, t_embed_input, context], output, name=name)\n",
        "\n",
        "        if download_weights:\n",
        "            diffusion_model_weights_fpath = keras.utils.get_file(\n",
        "                origin=\"https://huggingface.co/ianstenbit/keras-sd2.1/resolve/main/diffusion_model_v2_1.h5\",\n",
        "                file_hash=\"c31730e91111f98fe0e2dbde4475d381b5287ebb9672b1821796146a25c5132d\",\n",
        "            )\n",
        "            self.load_weights(diffusion_model_weights_fpath)\n",
        "\n",
        "\n",
        "class ResBlock(keras.layers.Layer):\n",
        "    def __init__(self, output_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.output_dim = output_dim\n",
        "        self.entry_flow = [\n",
        "            keras.layers.GroupNormalization(epsilon=1e-5),\n",
        "            keras.layers.Activation(\"swish\"),\n",
        "            PaddedConv2D(output_dim, 3, padding=1),\n",
        "        ]\n",
        "        self.embedding_flow = [\n",
        "            keras.layers.Activation(\"swish\"),\n",
        "            keras.layers.Dense(output_dim),\n",
        "        ]\n",
        "        self.exit_flow = [\n",
        "            keras.layers.GroupNormalization(epsilon=1e-5),\n",
        "            keras.layers.Activation(\"swish\"),\n",
        "            PaddedConv2D(output_dim, 3, padding=1),\n",
        "        ]\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        if input_shape[0][-1] != self.output_dim:\n",
        "            self.residual_projection = PaddedConv2D(self.output_dim, 1)\n",
        "        else:\n",
        "            self.residual_projection = lambda x: x\n",
        "\n",
        "    def call(self, inputs):\n",
        "        inputs, embeddings = inputs\n",
        "        x = inputs\n",
        "        for layer in self.entry_flow:\n",
        "            x = layer(x)\n",
        "        for layer in self.embedding_flow:\n",
        "            embeddings = layer(embeddings)\n",
        "        x = x + embeddings[:, None, None]\n",
        "        for layer in self.exit_flow:\n",
        "            x = layer(x)\n",
        "        return x + self.residual_projection(inputs)\n",
        "\n",
        "\n",
        "class SpatialTransformer(keras.layers.Layer):\n",
        "    \"\"\" transform the image with respect to the context embedding\"\"\"\n",
        "    def __init__(self, num_heads, head_size, fully_connected=False, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.norm = keras.layers.GroupNormalization(epsilon=1e-5)\n",
        "        channels = num_heads * head_size\n",
        "        if fully_connected:\n",
        "            self.proj1 = keras.layers.Dense(num_heads * head_size)\n",
        "        else:\n",
        "            self.proj1 = PaddedConv2D(num_heads * head_size, 1)\n",
        "        self.transformer_block = BasicTransformerBlock(\n",
        "            channels, num_heads, head_size\n",
        "        )\n",
        "        if fully_connected:\n",
        "            self.proj2 = keras.layers.Dense(channels)\n",
        "        else:\n",
        "            self.proj2 = PaddedConv2D(channels, 1)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        inputs, context = inputs\n",
        "        _, h, w, c = inputs.shape\n",
        "        x = self.norm(inputs)\n",
        "        x = self.proj1(x)\n",
        "        x = tf.reshape(x, (-1, h * w, c))\n",
        "        x = self.transformer_block([x, context])\n",
        "        x = tf.reshape(x, (-1, h, w, c))\n",
        "        return self.proj2(x) + inputs\n",
        "\n",
        "\n",
        "class BasicTransformerBlock(keras.layers.Layer):\n",
        "    def __init__(self, dim, num_heads, head_size, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.norm1 = keras.layers.LayerNormalization(epsilon=1e-5)\n",
        "        self.attn1 = CrossAttention(num_heads, head_size)\n",
        "        self.norm2 = keras.layers.LayerNormalization(epsilon=1e-5)\n",
        "        self.attn2 = CrossAttention(num_heads, head_size)\n",
        "        self.norm3 = keras.layers.LayerNormalization(epsilon=1e-5)\n",
        "        self.geglu = GEGLU(dim * 4)\n",
        "        self.dense = keras.layers.Dense(dim)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        inputs, context = inputs\n",
        "        x = self.attn1([self.norm1(inputs), None]) + inputs\n",
        "        x = self.attn2([self.norm2(x), context]) + x\n",
        "        return self.dense(self.geglu(self.norm3(x))) + x\n",
        "\n",
        "\n",
        "class CrossAttention(keras.layers.Layer):\n",
        "    def __init__(self, num_heads, head_size, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.to_q = keras.layers.Dense(num_heads * head_size, use_bias=False)\n",
        "        self.to_k = keras.layers.Dense(num_heads * head_size, use_bias=False)\n",
        "        self.to_v = keras.layers.Dense(num_heads * head_size, use_bias=False)\n",
        "        self.scale = head_size**-0.5\n",
        "        self.num_heads = num_heads\n",
        "        self.head_size = head_size\n",
        "        self.out_proj = keras.layers.Dense(num_heads * head_size)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        inputs, context = inputs\n",
        "        context = inputs if context is None else context\n",
        "        q, k, v = self.to_q(inputs), self.to_k(context), self.to_v(context)\n",
        "        q = tf.reshape(q, (-1, inputs.shape[1], self.num_heads, self.head_size))\n",
        "        k = tf.reshape(\n",
        "            k, (-1, context.shape[1], self.num_heads, self.head_size)\n",
        "        )\n",
        "        v = tf.reshape(\n",
        "            v, (-1, context.shape[1], self.num_heads, self.head_size)\n",
        "        )\n",
        "\n",
        "        q = tf.transpose(q, (0, 2, 1, 3))  # (bs, num_heads, time, head_size)\n",
        "        k = tf.transpose(k, (0, 2, 3, 1))  # (bs, num_heads, head_size, time)\n",
        "        v = tf.transpose(v, (0, 2, 1, 3))  # (bs, num_heads, time, head_size)\n",
        "\n",
        "        score = td_dot(q, k) * self.scale\n",
        "        weights = keras.activations.softmax(\n",
        "            score\n",
        "        )  # (bs, num_heads, time, time)\n",
        "        attn = td_dot(weights, v)\n",
        "        attn = tf.transpose(\n",
        "            attn, (0, 2, 1, 3)\n",
        "        )  # (bs, time, num_heads, head_size)\n",
        "        out = tf.reshape(\n",
        "            attn, (-1, inputs.shape[1], self.num_heads * self.head_size)\n",
        "        )\n",
        "        return self.out_proj(out)\n",
        "\n",
        "\n",
        "class Upsample(keras.layers.Layer):\n",
        "    def __init__(self, channels, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.ups = keras.layers.UpSampling2D(2)\n",
        "        self.conv = PaddedConv2D(channels, 3, padding=1)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return self.conv(self.ups(inputs))\n",
        "\n",
        "\n",
        "class GEGLU(keras.layers.Layer):\n",
        "    def __init__(self, output_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.output_dim = output_dim\n",
        "        self.dense = keras.layers.Dense(output_dim * 2)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.dense(inputs)\n",
        "        x, gate = x[..., : self.output_dim], x[..., self.output_dim :]\n",
        "        tanh_res = keras.activations.tanh(\n",
        "            gate * 0.7978845608 * (1 + 0.044715 * (gate**2))\n",
        "        )\n",
        "        return x * 0.5 * gate * (1 + tanh_res)\n",
        "\n",
        "\n",
        "def td_dot(a, b):\n",
        "    aa = tf.reshape(a, (-1, a.shape[2], a.shape[3]))\n",
        "    bb = tf.reshape(b, (-1, b.shape[2], b.shape[3]))\n",
        "    cc = keras.backend.batch_dot(aa, bb)\n",
        "    return tf.reshape(cc, (-1, a.shape[1], cc.shape[1], cc.shape[2]))"
      ]
    }
  ]
}