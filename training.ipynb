{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOyPwPJldzwBNz3uHyQQ12Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tensorflow-project/FineTuning/blob/main/training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/tensorflow-project/FineTuning\n",
        "#%cd FineTuning"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHvXPnQkeyzf",
        "outputId": "8d13af53-a879-4381-9d03-889101823149"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'FineTuning'...\n",
            "remote: Enumerating objects: 424, done.\u001b[K\n",
            "remote: Counting objects: 100% (60/60), done.\u001b[K\n",
            "remote: Compressing objects: 100% (53/53), done.\u001b[K\n",
            "remote: Total 424 (delta 37), reused 3 (delta 3), pack-reused 364\u001b[K\n",
            "Receiving objects: 100% (424/424), 93.42 MiB | 14.00 MiB/s, done.\n",
            "Resolving deltas: 100% (303/303), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "py_file_location = \"/content/FineTuning\"\n",
        "sys.path.append(os.path.abspath(py_file_location))\n",
        "py_file_location = \"/content/FineTuning/models\"\n",
        "sys.path.append(os.path.abspath(py_file_location))"
      ],
      "metadata": {
        "id": "SD_KkNtNSth_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "import os\n",
        "from google.colab import drive\n",
        "from PIL import Image\n",
        "import textual_inversion as txt\n",
        "#from textual_inversion import train_ds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZn6b3kEe4GP",
        "outputId": "0739f885-b7ea-4af9-e825-4598322217bd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (6.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.9/dist-packages (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.9/dist-packages (from h5py) (1.22.4)\n",
            "By using this model checkpoint, you acknowledge that its usage is subject to the terms of the CreativeML Open RAIL-M license at https://raw.githubusercontent.com/CompVis/stable-diffusion/main/LICENSE\n",
            "Downloading data from https://github.com/openai/CLIP/blob/main/clip/bpe_simple_vocab_16e6.txt.gz?raw=true\n",
            "1356917/1356917 [==============================] - 0s 0us/step\n",
            "Downloading data from https://i.imgur.com/9zAwPyt.jpg\n",
            "8784/8784 [==============================] - 0s 0us/step\n",
            "Downloading data from https://i.imgur.com/qCNFRl4.jpg\n",
            "14548/14548 [==============================] - 0s 0us/step\n",
            "Downloading data from https://i.imgur.com/Q8qiVEN.jpg\n",
            "8810/8810 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://i.imgur.com/SqFxJfM.jpg\n",
            "15475/15475 [==============================] - 0s 0us/step\n",
            "Downloading data from https://i.imgur.com/hFqqp3p.jpg\n",
            "7870/7870 [==============================] - 0s 0us/step\n",
            "Downloading data from https://i.imgur.com/uGkSrzg.jpg\n",
            "10306/10306 [==============================] - 0s 0us/step\n",
            "Downloading data from https://i.imgur.com/hlkuxBX.jpg\n",
            "11991/11991 [==============================] - 0s 0us/step\n",
            "Downloading data from https://i.imgur.com/kPH9XIh.jpg\n",
            "14897/14897 [==============================] - 0s 0us/step\n",
            "Downloading data from https://i.imgur.com/OR2oxyK.jpg\n",
            "8773/8773 [==============================] - 0s 0us/step\n",
            "Downloading data from https://i.imgur.com/mZswnIx.jpg\n",
            "6822/6822 [==============================] - 0s 0us/step\n",
            "Downloading data from https://i.imgur.com/TmlHZRY.png\n",
            "141537/141537 [==============================] - 0s 0us/step\n",
            "Downloading data from https://i.imgur.com/BmVIZlO.png\n",
            "201997/201997 [==============================] - 0s 0us/step\n",
            "Downloading data from https://huggingface.co/fchollet/stable-diffusion/resolve/main/kcv_encoder.h5\n",
            "492466864/492466864 [==============================] - 2s 0us/step\n",
            "Downloading data from https://huggingface.co/fchollet/stable-diffusion/resolve/main/kcv_diffusion_model.h5\n",
            "3439090152/3439090152 [==============================] - 18s 0us/step\n",
            "Downloading data from https://huggingface.co/fchollet/stable-diffusion/resolve/main/kcv_decoder.h5\n",
            "198180272/198180272 [==============================] - 1s 0us/step\n",
            "[[TensorShape([49409, 768])], [], []]\n",
            "Downloading data from https://huggingface.co/fchollet/stable-diffusion/resolve/main/vae_encoder.h5\n",
            "136824240/136824240 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sticker_embedding = []\n",
        "cosine_similarity = []\n",
        "broccoli = txt.get_embedding(\"broccoli\")\n",
        "cosine_similarity.append(txt.cosine_sim(broccoli, txt.get_embedding(txt.placeholder_token)))"
      ],
      "metadata": {
        "id": "6u0L8TKvdd_7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "epoch_num = list(range(epochs+1))\n",
        "txt.training(epoch=epochs, model=txt.stable_diffusion, data= txt.train_ds)"
      ],
      "metadata": {
        "id": "LD07AvQddezX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(epoch_num, cosine_similarity)\n",
        "plt.xlabel(\"Number of Epochs\")\n",
        "plt.ylabel(\"Cosine Similarity\")\n",
        "plt.title(\"Cosine Similarity between the basis and the new concept\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "M-DGSxVjd1xx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount(\"/content/drive\")\n",
        "path = '/content/drive/MyDrive/angryweeeights.npy'"
      ],
      "metadata": {
        "id": "ZnDt4BHJd40N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###get the weights of the text encoder and save the to google drive\n",
        "text_encoder_weights = np.array(stable_diffusion.text_encoder.get_weights())\n",
        "\n",
        "### Save the weights array to a file on your Google Drive\n",
        "np.save(path, text_encoder_weights)"
      ],
      "metadata": {
        "id": "1wBN4HdceChs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###load the array of the weights of the text encoder from the last training from google drive\n",
        "text_encoder_weights = np.load(path, allow_pickle=True)\n",
        "\n",
        "### Set the weights of the text encoder\n",
        "stable_diffusion.text_encoder.set_weights(text_encoder_weights)"
      ],
      "metadata": {
        "id": "bsNpooPgeLHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "drive_folder = '/content/drive/MyDrive/angrybildeeer/'\n",
        "\n",
        "### get the number, we stopped the last time to name our pictures, to ensure each picture gets a different name\n",
        "i_file = os.path.join(drive_folder, 'i.txt')\n",
        "if os.path.isfile(i_file):\n",
        "    with open(i_file, 'r') as f:\n",
        "        i = int(f.read())\n",
        "else:\n",
        "    i = 0\n",
        "\n",
        "for j in range(10):\n",
        "    generated = stable_diffusion.text_to_image(\n",
        "    f\" a angry {placeholder_token}.\", batch_size=1,  num_steps=25 )\n",
        "    broc = generated[0]\n",
        "\n",
        "    ### convert the array generated from our stable diffusion model into a picture\n",
        "    broc = Image.fromarray(broc, mode='RGB')\n",
        "\n",
        "    broc.save(f'image_{i}.jpg')\n",
        "\n",
        "    ### save the picture to google drive\n",
        "    local_path = f'image_{i}.jpg'\n",
        "    drive_path = os.path.join(drive_folder, f'image_{i}.jpg')  # Use f-string to include variable in file name\n",
        "    shutil.copy(local_path, drive_path)\n",
        "\n",
        "    ### store the value of i in the file, to ensure no picture will have the same name\n",
        "    i += 1\n",
        "    with open(i_file, 'w') as f:\n",
        "        f.write(str(i))"
      ],
      "metadata": {
        "id": "b6_FS5jfeROz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}